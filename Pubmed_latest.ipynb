{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articale S.No 0 article_id 12798312\n",
      "Articale S.No 1 article_id 17951059\n",
      "DataFrame is written to Excel File successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Overall_Published_Count</th>\n",
       "      <th>Related no published articles</th>\n",
       "      <th>Latest_published_date</th>\n",
       "      <th>Latest_published article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Author_name, Overall_Published_Count, Related no published articles, Latest_published_date, Latest_published article_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "import ssl\n",
    "import json\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def get_related_article_list(keyword,num):\n",
    "    url=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=NUM&sort=relevance&term=KEYWORD\"\n",
    "    keyword = keyword.replace(\" \",\"+\")\n",
    "    keyword = keyword.replace(\"(\",\"%28\")\n",
    "    keyword = keyword.replace(\")\",\"%29\")\n",
    "    url = url.replace('NUM', str(num))\n",
    "    url = url.replace('KEYWORD', keyword)\n",
    "    webpage = urllib.request.urlopen(url).read()\n",
    "    dict_page =json.loads(webpage)\n",
    "    # print(dict_page)\n",
    "    idlist = dict_page[\"esearchresult\"][\"idlist\"]\n",
    "    return idlist\n",
    "def get_authors_name(i,article_dict,article_id):\n",
    "    print(\"Articale S.No {} article_id {}\".format(i,article_id))\n",
    "    article_id = str(article_id)\n",
    "    authors = article_dict['result'][article_id][\"authors\"]\n",
    "    return authors\n",
    "\n",
    "def get_authors_data(idlist,keyword,data):\n",
    "#     data=[]\n",
    "    for i in range(len(idlist)):\n",
    "        url =\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id=idlist&retmode=json\"\n",
    "        url = url.replace('idlist', idlist[i])\n",
    "        articleResponse = urllib.request.urlopen(url).read()\n",
    "        dict_article =json.loads(articleResponse)\n",
    "        authors_list = get_authors_name(i,dict_article,idlist[i])\n",
    "        for i in range(len(authors_list)):\n",
    "            author_name=authors_list[i][\"name\"]\n",
    "            author_name = author_name.replace(\" \",\"+\")\n",
    "            url = \"https://pubmed.ncbi.nlm.nih.gov/?term=KEYWORD\"\n",
    "            url = url.replace(\"KEYWORD\",author_name)         \n",
    "            author_all_Topic_res = requests.get(url)\n",
    "            author_all_Topic_soup = BeautifulSoup(author_all_Topic_res.content, \"html.parser\")\n",
    "            author_all_Topic_soup_res = author_all_Topic_soup.find('div', class_=\"results-amount\")\n",
    "            if(author_all_Topic_soup_res is not None):\n",
    "                overall_number_of_articles = int(author_all_Topic_soup_res.find('span',class_=\"value\").string.replace(\",\",\"\"))\n",
    "            else:\n",
    "                overall_number_of_articles = 1\n",
    "            if(overall_number_of_articles>=7 and overall_number_of_articles <=60):\n",
    "                author_related_Topic = author_name +\" AND \"+keyword\n",
    "                author_related_Topic = author_related_Topic.replace(\" \",\"+\")\n",
    "                url = \"https://pubmed.ncbi.nlm.nih.gov/?term=KEYWORD\"\n",
    "                url = url.replace(\"KEYWORD\",author_related_Topic)         \n",
    "                r = requests.get(url)\n",
    "#                 print(url)\n",
    "                soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "                number_of_articles = soup.find('span', class_=\"value\")\n",
    "                number_of_articles = 1 if (number_of_articles is None ) else int(number_of_articles.string.replace(\",\",\"\"))\n",
    "                if(number_of_articles>=3 and number_of_articles <=55):\n",
    "                    articles_pub_year_list = soup.find_all('span',class_=\"docsum-journal-citation short-journal-citation\")\n",
    "                    article_year = list(map(lambda x:str(x).split('.')[1].strip(),articles_pub_year_list))\n",
    "                    articles_pub_dates = []\n",
    "                    article_ids=[]\n",
    "                    article_years=[]\n",
    "                    for i in range(len(article_year)):\n",
    "                        if article_year[i] in (\"2022\",\"2021\"):\n",
    "                            article_date_string = str(articles_pub_year_list[i].find_previous_sibling(\"span\",class_=\"docsum-journal-citation full-journal-citation\")).split(\";\")[0].split(\".\")[1].strip()[:8]\n",
    "                            if(len(article_date_string)==8):\n",
    "                                article_pub_date = dt.strptime(article_date_string,'%Y %b')\n",
    "                            else:\n",
    "                                article_pub_date = dt.strptime(article_date_string,'%Y')\n",
    "                            articles_pub_dates.append(article_pub_date.date())\n",
    "                            article_ids.append(articles_pub_year_list[i].next_sibling.next_sibling.find('span',class_=\"docsum-pmid\").string)\n",
    "                            article_years.append(article_year[i])\n",
    "\n",
    "                    authors_details=[]\n",
    "                    if(('2021' or '2022') in article_year):\n",
    "                        latest_date = max(articles_pub_dates,default=0)\n",
    "                        latest_date_index = articles_pub_dates.index(latest_date)\n",
    "                        latest_article_id = article_ids[latest_date_index]\n",
    "                        authors_details.append(author_name)\n",
    "                        authors_details.append(overall_number_of_articles)\n",
    "                        authors_details.append(number_of_articles)\n",
    "                        authors_details.append(latest_date)\n",
    "                        authors_details.append(latest_article_id)\n",
    "                        data.append(authors_details)\n",
    "                        print(\"Name {} overall_count {} related_count {} latest_pub date {} article_Id {}\".format(author_name,overall_number_of_articles,number_of_articles,latest_date,latest_article_id))\n",
    "    return data\n",
    "# Enter the keyWord required to search\n",
    "keyword = '(pyrazole-Based inhibitors OR heteroaromatic scaffolds OR hydroxamate OR hydroxamic acid) AND (meprin OR metalloproteases OR metalloproteinases OR Synthesis OR Structure )';\n",
    "#enter the number of articles like 100,200,300 count etc\n",
    "num=100\n",
    "# we can exclude already searched article Id's by slicing like below line\n",
    "# idlist = :get_related_article_list(keyword,num)[100:] \n",
    "idlist = get_related_article_list(keyword,num)[23:25]\n",
    "data=[]\n",
    "data_res = get_authors_data(idlist,keyword,data)\n",
    "df = pd.DataFrame(data_res,columns=['Author_name',\"Overall_Published_Count\",'Related no published articles',\"Latest_published_date\",\"Latest_published article_id\"])\n",
    "file_name = 'pyrazole.csv'\n",
    "df=df.drop_duplicates()\n",
    "df.to_csv(file_name)\n",
    "print('DataFrame is written to Excel File successfully.')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Overall_Published_Count</th>\n",
       "      <th>Related no published articles</th>\n",
       "      <th>Latest_published_date</th>\n",
       "      <th>Latest_published article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yasodha+R</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>34047286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sasi+A</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>34539121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janardhanan+A</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>34539121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wanga+VO</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>35918646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oulo+MA</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>35918646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mkala+EM</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>35918646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Schwarzbach+AE</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>33242585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Denoeud+F</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>35015377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alsos+IG</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>35015377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yaradua+SS</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>34204211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alzahrani+DA</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>34204211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rhouma+A</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>34129651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yan+XR</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>35353675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Author_name  Overall_Published_Count  Related no published articles  \\\n",
       "0        Yasodha+R                       10                              4   \n",
       "1           Sasi+A                       41                              3   \n",
       "2    Janardhanan+A                       14                              3   \n",
       "3         Wanga+VO                       13                              8   \n",
       "4          Oulo+MA                       11                              8   \n",
       "5         Mkala+EM                       16                              8   \n",
       "6   Schwarzbach+AE                       14                              3   \n",
       "7        Denoeud+F                       41                              3   \n",
       "8         Alsos+IG                       35                              4   \n",
       "9       Yaradua+SS                        7                              4   \n",
       "10    Alzahrani+DA                       17                              4   \n",
       "11        Rhouma+A                       35                              3   \n",
       "13          Yan+XR                       58                             18   \n",
       "\n",
       "   Latest_published_date Latest_published article_id  \n",
       "0             2021-01-01                    34047286  \n",
       "1             2021-08-01                    34539121  \n",
       "2             2021-08-01                    34539121  \n",
       "3             2022-08-01                    35918646  \n",
       "4             2022-08-01                    35918646  \n",
       "5             2022-08-01                    35918646  \n",
       "6             2021-03-01                    33242585  \n",
       "7             2022-07-01                    35015377  \n",
       "8             2022-07-01                    35015377  \n",
       "9             2021-06-01                    34204211  \n",
       "10            2021-06-01                    34204211  \n",
       "11            2021-06-01                    34129651  \n",
       "13            2022-03-01                    35353675  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d03ee6d16408b79e66007fa1c33457bec982be8699a17b1f62696a8a8e5a4e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
